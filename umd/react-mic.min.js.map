{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///react-mic.min.js","webpack:///webpack/bootstrap dfad4301de8ad1bfb379","webpack:///./src/index.js","webpack:///./~/audio-recorder-polyfill/index.js","webpack:///./~/audio-recorder-polyfill/wave-encoder.js","webpack:///./src/components/ReactMic.js","webpack:///./src/libs/AudioContext.js","webpack:///./src/libs/AudioPlayer.js","webpack:///./src/libs/MicrophoneRecorder.js","webpack:///external {\"root\":\"React\",\"commonjs2\":\"react\",\"commonjs\":\"react\",\"amd\":\"react\"}"],"names":["root","factory","exports","module","require","define","amd","this","__WEBPACK_EXTERNAL_MODULE_7__","modules","__webpack_require__","moduleId","installedModules","i","l","call","m","c","value","d","name","getter","o","Object","defineProperty","configurable","enumerable","get","n","__esModule","object","property","prototype","hasOwnProperty","p","s","__webpack_exports__","__WEBPACK_IMPORTED_MODULE_0__components_ReactMic__","createWorker","fn","js","toString","replace","blob","Blob","Worker","URL","createObjectURL","MediaRecorder","stream","state","em","document","createDocumentFragment","encoder","recorder","addEventListener","e","event","Event","data","type","mimeType","dispatchEvent","context","AudioContext","window","webkitAudioContext","start","timeslice","input","createMediaStreamSource","processor","createScriptProcessor","onaudioprocess","postMessage","inputBuffer","getChannelData","connect","destination","slicing","setInterval","requestData","stop","clearInterval","pause","resume","sampleRate","apply","arguments","removeEventListener","isTypeSupported","test","notSupported","navigator","mediaDevices","encode","buffer","length","Uint8Array","BYTES_PER_SAMPLE","index","sample","recorded","push","dump","bufferLength","wav","view","DataView","setUint32","setUint16","set","onmessage","_classCallCheck","instance","Constructor","TypeError","_possibleConstructorReturn","self","ReferenceError","_inherits","subClass","superClass","create","constructor","writable","setPrototypeOf","__proto__","__WEBPACK_IMPORTED_MODULE_0_react__","__WEBPACK_IMPORTED_MODULE_0_react___default","__WEBPACK_IMPORTED_MODULE_1__libs_MicrophoneRecorder__","__WEBPACK_IMPORTED_MODULE_2__libs_AudioPlayer__","ReactMic","_Component","props","_this","microphoneRecorder","componentDidMount","_props","onSave","onStop","onStart","onData","audioElem","audioBitsPerSecond","options","setState","render","_props2","record","children","startRecording","stopRecording","a","createElement","Fragment","defaultProps","className","audioCtx","analyser","createAnalyser","getAudioContext","getAnalyser","__WEBPACK_IMPORTED_MODULE_0__AudioContext__","audioSource","AudioPlayer","undefined","source","createMediaElementSource","__WEBPACK_IMPORTED_MODULE_0_audio_recorder_polyfill__","__WEBPACK_IMPORTED_MODULE_0_audio_recorder_polyfill___default","MicrophoneRecorder","mediaRecorder","chunks","startTime","mediaOptions","onStartCallback","onStopCallback","onSaveCallback","onDataCallback","constraints","audio","getUserMedia","webkitGetUserMedia","mozGetUserMedia","msGetUserMedia","Date","now","then","str","alert","getTracks","forEach","blobObject","stopTime","blobURL"],"mappings":";;;;CAAA,SAAAA,EAAAC,GACA,gBAAAC,UAAA,gBAAAC,QACAA,OAAAD,QAAAD,EAAAG,QAAA,UACA,kBAAAC,gBAAAC,IACAD,QAAA,SAAAJ,GACA,gBAAAC,SACAA,QAAA,aAAAD,EAAAG,QAAA,UAEAJ,EAAA,aAAAC,EAAAD,EAAA,QACCO,KAAA,SAAAC,GACD,MCAgB,UAAUC,GCN1B,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAT,OAGA,IAAAC,GAAAS,EAAAD,IACAE,EAAAF,EACAG,GAAA,EACAZ,WAUA,OANAO,GAAAE,GAAAI,KAAAZ,EAAAD,QAAAC,IAAAD,QAAAQ,GAGAP,EAAAW,GAAA,EAGAX,EAAAD,QAvBA,GAAAU,KA+DA,OAnCAF,GAAAM,EAAAP,EAGAC,EAAAO,EAAAL,EAGAF,EAAAG,EAAA,SAAAK,GAA2C,MAAAA,IAG3CR,EAAAS,EAAA,SAAAjB,EAAAkB,EAAAC,GACAX,EAAAY,EAAApB,EAAAkB,IACAG,OAAAC,eAAAtB,EAAAkB,GACAK,cAAA,EACAC,YAAA,EACAC,IAAAN,KAMAX,EAAAkB,EAAA,SAAAzB,GACA,GAAAkB,GAAAlB,KAAA0B,WACA,WAA2B,MAAA1B,GAAA,SAC3B,WAAiC,MAAAA,GAEjC,OADAO,GAAAS,EAAAE,EAAA,IAAAA,GACAA,GAIAX,EAAAY,EAAA,SAAAQ,EAAAC,GAAsD,MAAAR,QAAAS,UAAAC,eAAAlB,KAAAe,EAAAC,IAGtDrB,EAAAwB,EAAA,GAGAxB,IAAAyB,EAAA,KDgBM,SAAUhC,EAAQiC,EAAqB1B,GAE7C,YACAa,QAAOC,eAAeY,EAAqB,cAAgBlB,OAAO,GAC7C,IAAImB,GAAqD3B,EAAoB,EElFlG0B,GAAA,QAAeC,EAAA,GFyFT,SAAUlC,EAAQD,EAASQ,GGzFjC,QAAA4B,GAAAC,GACA,GAAAC,GAAAD,EACAE,WACAC,QAAA,uBAAkC,IAClCA,QAAA,KAAe,IACfC,EAAA,GAAAC,OAAAJ,GACA,WAAAK,QAAAC,IAAAC,gBAAAJ,IAiBA,QAAAK,GAAAC,GAKA1C,KAAA0C,SAMA1C,KAAA2C,MAAA,WAEA3C,KAAA4C,GAAAC,SAAAC,yBACA9C,KAAA+C,QAAAhB,EAAAU,EAAAM,QAEA,IAAAC,GAAAhD,IACAA,MAAA+C,QAAAE,iBAAA,mBAAAC,GACA,GAAAC,GAAA,GAAAC,OAAA,gBACAD,GAAAE,KAAA,GAAAhB,OAAAa,EAAAG,OAAqCC,KAAAN,EAAAO,WACrCP,EAAAJ,GAAAY,cAAAL,GACA,aAAAH,EAAAL,OACAK,EAAAJ,GAAAY,cAAA,GAAAJ,OAAA,WA/CA,GAWAK,GAXAC,EAAAC,OAAAD,cAAAC,OAAAC,kBAoDAnB,GAAAhB,WAKA8B,SAAA,YAgBAM,MAAA,SAAAC,GACA,gBAAA9D,KAAA2C,MAAA,CACA3C,KAAA2C,MAAA,YAEAc,IACAA,EAAA,GAAAC,GAEA,IAAAK,GAAAN,EAAAO,wBAAAhE,KAAA0C,QACAuB,EAAAR,EAAAS,sBAAA,UAEAlB,EAAAhD,IACAiE,GAAAE,eAAA,SAAAjB,GACA,cAAAF,EAAAL,OACAK,EAAAD,QAAAqB,aACA,SAAAlB,EAAAmB,YAAAC,eAAA,MAKAP,EAAAQ,QAAAN,GACAA,EAAAM,QAAAd,EAAAe,aAEAxE,KAAA4C,GAAAY,cAAA,GAAAJ,OAAA,UAEAU,IACA9D,KAAAyE,QAAAC,YAAA,WACA,cAAA1B,EAAAL,OAAAK,EAAA2B,eACSb,MAeTc,KAAA,WACA,aAAA5E,KAAA2C,QACA3C,KAAA2E,cACA3E,KAAA2C,MAAA,WACAkC,cAAA7E,KAAAyE,WAcAK,MAAA,WACA,cAAA9E,KAAA2C,QACA3C,KAAA2C,MAAA,SACA3C,KAAA4C,GAAAY,cAAA,GAAAJ,OAAA,YAcA2B,OAAA,WACA,WAAA/E,KAAA2C,QACA3C,KAAA2C,MAAA,YACA3C,KAAA4C,GAAAY,cAAA,GAAAJ,OAAA,aAcAuB,YAAA,WACA,aAAA3E,KAAA2C,OACA3C,KAAA+C,QAAAqB,aAAA,OAAAX,EAAAuB,cAiBA/B,iBAAA,WACAjD,KAAA4C,GAAAK,iBAAAgC,MAAAjF,KAAA4C,GAAAsC,YAWAC,oBAAA,WACAnF,KAAA4C,GAAAuC,oBAAAF,MAAAjF,KAAA4C,GAAAsC,YAUA1B,cAAA,WACAxD,KAAA4C,GAAAY,cAAAyB,MAAAjF,KAAA4C,GAAAsC,aAaAzC,EAAA2C,gBAAA,SAAA7B,GACA,qBAAA8B,KAAA9B,IAYAd,EAAA6C,cAAAC,UAAAC,eAAA9B,EAYAjB,EAAAM,QAAA5C,EAAA,GAEAP,EAAAD,QAAA8C,GHkGM,SAAU7C,EAAQD,GI1VxBC,EAAAD,QAAA,WAKA,QAAA8F,GAAAC,GAGA,OAFAC,GAAAD,EAAAC,OACAtC,EAAA,GAAAuC,YAAAD,EAAAE,GACAvF,EAAA,EAAmBA,EAAAqF,EAAYrF,IAAA,CAC/B,GAAAwF,GAAAxF,EAAAuF,EACAE,EAAAL,EAAApF,EACAyF,GAAA,EACAA,EAAA,EACOA,GAAA,IACPA,GAAA,GAEAA,GAAA,MACA1C,EAAAyC,GAAAC,EACA1C,EAAAyC,EAAA,GAAAC,GAAA,EAEAC,EAAAC,KAAA5C,GAGA,QAAA6C,GAAAlB,GACA,GAAAmB,GAAAH,EAAAL,OAAAK,EAAA,GAAAL,OAAA,EACAA,EAAAK,EAAAL,OAAAQ,EACAC,EAAA,GAAAR,YAAA,GAAAD,GACAU,EAAA,GAAAC,UAAAF,EAAAV,OAGAW,GAAAE,UAAA,iBAEAF,EAAAE,UAAA,KAAAZ,GAAA,GAEAU,EAAAE,UAAA,iBAEAF,EAAAE,UAAA,kBAEAF,EAAAE,UAAA,UAEAF,EAAAG,UAAA,SAEAH,EAAAG,UAAA,SAEAH,EAAAE,UAAA,GAAAvB,GAAA,GAEAqB,EAAAE,UAAA,GAAAvB,EAAAa,GAAA,GAEAQ,EAAAG,UAAA,GAAAX,GAAA,GAEAQ,EAAAG,UAAA,KAAAX,GAAA,GAEAQ,EAAAE,UAAA,kBAEAF,EAAAE,UAAA,GAAAZ,GAAA,EAEA,QAAArF,GAAA,EAAmBA,EAAA0F,EAAAL,OAAqBrF,IACxC8F,EAAAK,IAAAT,EAAA1F,KAAA6F,EAAA,GAGAH,MACA5B,YAAAgC,EAAAV,QAAAU,EAAAV,SA5DA,GAAAG,GAAA,EAEAG,IA6DAU,WAAA,SAAAxD,GACA,WAAAA,EAAAG,KAAA,GACAoC,EAAAvC,EAAAG,KAAA,IAEA6C,EAAAhD,EAAAG,KAAA,OJsWM,SAAUzD,EAAQiC,EAAqB1B,GAE7C,YAMA,SAASwG,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCAEhH,QAASC,GAA2BC,EAAMxG,GAAQ,IAAKwG,EAAQ,KAAM,IAAIC,gBAAe,4DAAgE,QAAOzG,GAAyB,gBAATA,IAAqC,kBAATA,GAA8BwG,EAAPxG,EAElO,QAAS0G,GAAUC,EAAUC,GAAc,GAA0B,kBAAfA,IAA4C,OAAfA,EAAuB,KAAM,IAAIN,WAAU,iEAAoEM,GAAeD,GAAS1F,UAAYT,OAAOqG,OAAOD,GAAcA,EAAW3F,WAAa6F,aAAe3G,MAAOwG,EAAUhG,YAAY,EAAOoG,UAAU,EAAMrG,cAAc,KAAekG,IAAYpG,OAAOwG,eAAiBxG,OAAOwG,eAAeL,EAAUC,GAAcD,EAASM,UAAYL,GAT5c,GAAIM,GAAsCvH,EAAoB,GAC1DwH,EAA8CxH,EAAoBkB,EAAEqG,GACpEE,EAAyDzH,EAAoB,GAC7E0H,EAAkD1H,EAAoB,EAChEA,GAAoBS,EAAEiB,EAAqB,IAAK,WAAa,MAAOiG,IAiBnG,IK1bqBA,GL0bN,SAAUC,GKzbvB,QAAAD,GAAYE,GAAOrB,EAAA3G,KAAA8H,EAAA,IAAAG,GAAAlB,EAAA/G,KACjB+H,EAAAvH,KAAAR,KAAMgI,GADW,OAEjBC,GAAKtF,OACHuF,mBAAoB,MAHLD,ELsfnB,MA5DAf,GAAUY,EAAUC,GAapBD,EAASrG,UKhcT0G,kBLgcuC,WKhcnB,GAAAC,GACmEpI,KAAKgI,MAAlFK,EADUD,EACVC,OAAQC,EADEF,EACFE,OAAQC,EADNH,EACMG,QAASC,EADfJ,EACeI,OAAQC,EADvBL,EACuBK,UAAWC,EADlCN,EACkCM,mBAAoBnF,EADtD6E,EACsD7E,SAClEoF,GACJD,qBACAnF,WAGEkF,GACFZ,EAAA,EAAYR,OAAOoB,GAEnBzI,KAAK4I,UACHV,mBAAoB,GAAIN,GAAA,EAAmBW,EAASD,EAAQD,EAAQG,EAAQG,ML6clFb,EAASrG,UKxcToH,OLwc4B,WKxcnB,GAAAC,GAC8B9I,KAAKgI,MAAlCe,EADDD,EACCC,OAAQT,EADTQ,EACSR,OAAQU,EADjBF,EACiBE,SAChBd,EAAuBlI,KAAK2C,MAA5BuF,kBAUR,OARIA,KACEa,EACFb,EAAmBe,iBAEnBf,EAAmBgB,cAAcZ,IAI9BX,EAAAwB,EAAAC,cAACzB,EAAAwB,EAAME,SAAP,KAAiBL,ILmdnBlB,GKvf6BJ,EAAA,UAwCtCI,GAASwB,cACPC,UAAW,SACXb,mBAAoB,MACpBnF,SAAU,yBACVwF,QAAQ,IL0dJ,SAAUnJ,EAAQiC,EAAqB1B,GAE7C,YMlhBA,IAAMqJ,GAAW,IAAK7F,OAAOD,cAAgBC,OAAOC,oBAC9C6F,EAAWD,EAASE,iBAEpBhG,GACJiG,gBADoB,WAElB,MAAOH,IAGTI,YALoB,WAMlB,MAAOH,IAIX5H,GAAA,EAAe6B,GNshBT,SAAU9D,EAAQiC,EAAqB1B,GAE7C,YACqB,IAAI0J,GAA8C1J,EAAoB,GOpiBvF2J,SAEEC,GACJ1C,OADmB,SACZoB,GACL,GAAMe,GAAWK,EAAA,EAAaF,kBACxBF,EAAWI,EAAA,EAAaD,aAE9B,QAAmBI,KAAhBF,EAA0B,CAC3B,GAAMG,GAAST,EAASU,yBAAyBzB,EACjDwB,GAAO1F,QAAQkF,GACfK,EAAcG,EAGhBR,EAASlF,QAAQiF,EAAShF,cAI9B3C,GAAA,EAAekI,GP2iBT,SAAUnK,EAAQiC,EAAqB1B,GAE7C,YAIA,SAASwG,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAIC,WAAU,qCAH3F,GAAIqD,GAAwDhK,EAAoB,GAC5EiK,EAAgEjK,EAAoBkB,EAAE8I,EAChFhK,GAAoBS,EAAEiB,EAAqB,IAAK,WAAa,MAAOwI,IQjkBnG,IAAIC,UACAC,KACAC,SACAC,SACAC,SACAC,SACAC,SACAC,SAEEC,GAAgBC,OAAO,EAE7BxF,WAAUyF,aACRzF,UAAUyF,cACVzF,UAAU0F,oBACV1F,UAAU2F,iBACV3F,UAAU4F,cRokBZ,IQlkBqBd,GACnB,QAAAA,GAAY9B,EAASD,EAAQD,EAAQG,EAAQG,GAAS,GAAAV,GAAAjI,IAAA2G,GAAA3G,KAAAqK,GAAArK,KAQtDiJ,eAAiB,WACfuB,EAAYY,KAAKC,MACbf,IACE/E,UAAUC,aACZD,UAAUC,aAAawF,aAAaF,GAAaQ,KAAK,SAAAC,GACpDjB,EAAgB,GAAIF,GAAAjB,EAAcoC,GAC9Bb,GACFA,IAEFJ,EAAcrH,iBAAiB,gBAAiB,SAAAC,GAC9CqH,EAASrH,EAAEG,KACPwH,GACFA,EAAe3H,EAAEG,QAIrBiH,EAAczG,QACdyG,EAAcrH,iBAAiB,OAAQgF,EAAKK,UAG9CkD,MAAM,mDA5B0CxL,KAiCtDkJ,cAAgB,WACVoB,IACFA,EAAc1F,OACd0F,EAAc5H,OAAO+I,YAAY,GAAG7G,OACpC0F,EAAc5H,OAAO+I,YAAYC,QAAQ,SAAApL,GAAA,MAAKA,GAAEsE,UAElD0F,EAAgB,MAvCoCtK,KA0CtDsI,OAAS,WACP,GAAMqD,IACJvJ,KAAMmI,EACNC,YACAoB,SAAUjI,OAAOyH,KAAKC,MACtB1C,QAAS8B,EACToB,QAASlI,OAAOpB,IAAIC,gBAAgB+H,GAEtCA,MAEII,GACFA,EAAegB,GAEbf,GACFA,EAAee,IAvDjBjB,EAAkBnC,EAClBoC,EAAiBrC,EACjBsC,EAAiBvC,EACjBwC,EAAiBrC,EACjBiC,EAAe9B,IRkoBb,SAAU/I,EAAQD,GS3pBxBC,EAAAD,QAAAM,GTiqBM,SAAUL,EAAQD,EAASQ,GAEjCP,EAAOD,QAAUQ,EAAoB","file":"react-mic.min.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"react\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"react\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"react-mic\"] = factory(require(\"react\"));\n\telse\n\t\troot[\"react-mic\"] = factory(root[\"React\"]);\n})(this, function(__WEBPACK_EXTERNAL_MODULE_7__) {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition","(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"react\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"react\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"react-mic\"] = factory(require(\"react\"));\n\telse\n\t\troot[\"react-mic\"] = factory(root[\"React\"]);\n})(this, function(__WEBPACK_EXTERNAL_MODULE_7__) {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId])\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// identity function for calling harmony imports with the correct context\n/******/ \t__webpack_require__.i = function(value) { return value; };\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 8);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nObject.defineProperty(__webpack_exports__, \"__esModule\", { value: true });\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__components_ReactMic__ = __webpack_require__(3);\n\n\n/* harmony default export */ __webpack_exports__[\"default\"] = __WEBPACK_IMPORTED_MODULE_0__components_ReactMic__[\"a\" /* default */];\n\n/***/ }),\n/* 1 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar AudioContext = window.AudioContext || window.webkitAudioContext\n\nfunction createWorker (fn) {\n  var js = fn\n    .toString()\n    .replace(/^function\\s*\\(\\)\\s*{/, '')\n    .replace(/}$/, '')\n  var blob = new Blob([js])\n  return new Worker(URL.createObjectURL(blob))\n}\n\nvar context\n\n/**\n * Audio Recorder with MediaRecorder API.\n *\n * @param {MediaStream} stream The audio stream to record.\n *\n * @example\n * navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {\n *   var recorder = new MediaRecorder(stream)\n * })\n *\n * @class\n */\nfunction MediaRecorder (stream) {\n  /**\n   * The `MediaStream` passed into the constructor.\n   * @type {MediaStream}\n   */\n  this.stream = stream\n\n  /**\n   * The current state of recording process.\n   * @type {\"inactive\"|\"recording\"|\"paused\"}\n   */\n  this.state = 'inactive'\n\n  this.em = document.createDocumentFragment()\n  this.encoder = createWorker(MediaRecorder.encoder)\n\n  var recorder = this\n  this.encoder.addEventListener('message', function (e) {\n    var event = new Event('dataavailable')\n    event.data = new Blob([e.data], { type: recorder.mimeType })\n    recorder.em.dispatchEvent(event)\n    if (recorder.state === 'inactive') {\n      recorder.em.dispatchEvent(new Event('stop'))\n    }\n  })\n}\n\nMediaRecorder.prototype = {\n  /**\n   * The MIME type that is being used for recording.\n   * @type {string}\n   */\n  mimeType: 'audio/wav',\n\n  /**\n   * Begins recording media.\n   *\n   * @param {number} [timeslice] The milliseconds to record into each `Blob`.\n   *                             If this parameter isn’t included, single `Blob`\n   *                             will be recorded.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * recordButton.addEventListener('click', function () {\n   *   recorder.start()\n   * })\n   */\n  start: function start (timeslice) {\n    if (this.state === 'inactive') {\n      this.state = 'recording'\n\n      if (!context) {\n        context = new AudioContext()\n      }\n      var input = context.createMediaStreamSource(this.stream)\n      var processor = context.createScriptProcessor(2048, 1, 1)\n\n      var recorder = this\n      processor.onaudioprocess = function (e) {\n        if (recorder.state === 'recording') {\n          recorder.encoder.postMessage([\n            'encode', e.inputBuffer.getChannelData(0)\n          ])\n        }\n      }\n\n      input.connect(processor)\n      processor.connect(context.destination)\n\n      this.em.dispatchEvent(new Event('start'))\n\n      if (timeslice) {\n        this.slicing = setInterval(function () {\n          if (recorder.state === 'recording') recorder.requestData()\n        }, timeslice)\n      }\n    }\n  },\n\n  /**\n   * Stop media capture and raise `dataavailable` event with recorded data.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * finishButton.addEventListener('click', function () {\n   *   recorder.stop()\n   * })\n   */\n  stop: function stop () {\n    if (this.state !== 'inactive') {\n      this.requestData()\n      this.state = 'inactive'\n      clearInterval(this.slicing)\n    }\n  },\n\n  /**\n   * Pauses recording of media streams.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * pauseButton.addEventListener('click', function () {\n   *   recorder.pause()\n   * })\n   */\n  pause: function pause () {\n    if (this.state === 'recording') {\n      this.state = 'paused'\n      this.em.dispatchEvent(new Event('pause'))\n    }\n  },\n\n  /**\n   * Resumes media recording when it has been previously paused.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * resumeButton.addEventListener('click', function () {\n   *   recorder.resume()\n   * })\n   */\n  resume: function resume () {\n    if (this.state === 'paused') {\n      this.state = 'recording'\n      this.em.dispatchEvent(new Event('resume'))\n    }\n  },\n\n  /**\n   * Raise a `dataavailable` event containing the captured media.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * this.on('nextData', function () {\n   *   recorder.requestData()\n   * })\n   */\n  requestData: function requestData () {\n    if (this.state !== 'inactive') {\n      this.encoder.postMessage(['dump', context.sampleRate])\n    }\n  },\n\n  /**\n   * Add listener for specified event type.\n   *\n   * @param {\"start\"|\"stop\"|\"pause\"|\"resume\"|\"dataavailable\"} type Event type.\n   * @param {function} listener The listener function.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * recorder.addEventListener('dataavailable', function (e) {\n   *   audio.src = URL.createObjectURL(e.data)\n   * })\n   */\n  addEventListener: function addEventListener () {\n    this.em.addEventListener.apply(this.em, arguments)\n  },\n\n  /**\n   * Remove event listener.\n   *\n   * @param {\"start\"|\"stop\"|\"pause\"|\"resume\"|\"dataavailable\"} type Event type.\n   * @param {function} listener The same function used in `addEventListener`.\n   *\n   * @return {undefined}\n   */\n  removeEventListener: function removeEventListener () {\n    this.em.removeEventListener.apply(this.em, arguments)\n  },\n\n  /**\n   * Calls each of the listeners registered for a given event.\n   *\n   * @param {Event} event The event object.\n   *\n   * @return {boolean} Is event was no canceled by any listener.\n   */\n  dispatchEvent: function dispatchEvent () {\n    this.em.dispatchEvent.apply(this.em, arguments)\n  }\n}\n\n/**\n * Returns `true` if the MIME type specified is one the polyfill can record.\n *\n * This polyfill supports only `audio/wav`.\n *\n * @param {string} mimeType The mimeType to check.\n *\n * @return {boolean} `true` on `audio/wav` MIME type.\n */\nMediaRecorder.isTypeSupported = function isTypeSupported (mimeType) {\n  return /audio\\/wave?/.test(mimeType)\n}\n\n/**\n * `true` if MediaRecorder can not be polyfilled in the current browser.\n * @type {boolean}\n *\n * @example\n * if (MediaRecorder.notSupported) {\n *   showWarning('Audio recording is not supported in this browser')\n * }\n */\nMediaRecorder.notSupported = !navigator.mediaDevices || !AudioContext\n\n/**\n * Converts RAW audio buffer to compressed audio files.\n * It will be loaded to Web Worker.\n * By default, WAVE encoder will be used.\n * @type {function}\n *\n * @example\n * MediaRecorder.prototype.mimeType = 'audio/ogg'\n * MediaRecorder.encoder = oggEncoder\n */\nMediaRecorder.encoder = __webpack_require__(2)\n\nmodule.exports = MediaRecorder\n\n\n/***/ }),\n/* 2 */\n/***/ (function(module, exports) {\n\n// Copied from https://github.com/chris-rudmin/Recorderjs\n\nmodule.exports = function () {\n  var BYTES_PER_SAMPLE = 2\n\n  var recorded = []\n\n  function encode (buffer) {\n    var length = buffer.length\n    var data = new Uint8Array(length * BYTES_PER_SAMPLE)\n    for (var i = 0; i < length; i++) {\n      var index = i * BYTES_PER_SAMPLE\n      var sample = buffer[i]\n      if (sample > 1) {\n        sample = 1\n      } else if (sample < -1) {\n        sample = -1\n      }\n      sample = sample * 32768\n      data[index] = sample\n      data[index + 1] = sample >> 8\n    }\n    recorded.push(data)\n  }\n\n  function dump (sampleRate) {\n    var bufferLength = recorded.length ? recorded[0].length : 0\n    var length = recorded.length * bufferLength\n    var wav = new Uint8Array(44 + length)\n    var view = new DataView(wav.buffer)\n\n    // RIFF identifier 'RIFF'\n    view.setUint32(0, 1380533830, false)\n    // file length minus RIFF identifier length and file description length\n    view.setUint32(4, 36 + length, true)\n    // RIFF type 'WAVE'\n    view.setUint32(8, 1463899717, false)\n    // format chunk identifier 'fmt '\n    view.setUint32(12, 1718449184, false)\n    // format chunk length\n    view.setUint32(16, 16, true)\n    // sample format (raw)\n    view.setUint16(20, 1, true)\n    // channel count\n    view.setUint16(22, 1, true)\n    // sample rate\n    view.setUint32(24, sampleRate, true)\n    // byte rate (sample rate * block align)\n    view.setUint32(28, sampleRate * BYTES_PER_SAMPLE, true)\n    // block align (channel count * bytes per sample)\n    view.setUint16(32, BYTES_PER_SAMPLE, true)\n    // bits per sample\n    view.setUint16(34, 8 * BYTES_PER_SAMPLE, true)\n    // data chunk identifier 'data'\n    view.setUint32(36, 1684108385, false)\n    // data chunk length\n    view.setUint32(40, length, true)\n\n    for (var i = 0; i < recorded.length; i++) {\n      wav.set(recorded[i], i * bufferLength + 44)\n    }\n\n    recorded = []\n    postMessage(wav.buffer, [wav.buffer])\n  }\n\n  onmessage = function (e) {\n    if (e.data[0] === 'encode') {\n      encode(e.data[1])\n    } else {\n      dump(e.data[1])\n    }\n  }\n}\n\n\n/***/ }),\n/* 3 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_react__ = __webpack_require__(7);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_react___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_react__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1__libs_MicrophoneRecorder__ = __webpack_require__(6);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2__libs_AudioPlayer__ = __webpack_require__(5);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return ReactMic; });\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }\n\n// cool blog article on how to do this: http://www.smartjava.org/content/exploring-html5-web-audio-visualizing-sound\n// https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\n\n// distortion curve for the waveshaper, thanks to Kevin Ennis\n// http://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion\n\n\n\n\n\nvar ReactMic = function (_Component) {\n  _inherits(ReactMic, _Component);\n\n  function ReactMic(props) {\n    _classCallCheck(this, ReactMic);\n\n    var _this = _possibleConstructorReturn(this, _Component.call(this, props));\n\n    _this.state = {\n      microphoneRecorder: null\n    };\n    return _this;\n  }\n\n  ReactMic.prototype.componentDidMount = function componentDidMount() {\n    var _props = this.props,\n        onSave = _props.onSave,\n        onStop = _props.onStop,\n        onStart = _props.onStart,\n        onData = _props.onData,\n        audioElem = _props.audioElem,\n        audioBitsPerSecond = _props.audioBitsPerSecond,\n        mimeType = _props.mimeType;\n\n    var options = {\n      audioBitsPerSecond: audioBitsPerSecond,\n      mimeType: mimeType\n    };\n\n    if (audioElem) {\n      __WEBPACK_IMPORTED_MODULE_2__libs_AudioPlayer__[\"a\" /* default */].create(audioElem);\n    } else {\n      this.setState({\n        microphoneRecorder: new __WEBPACK_IMPORTED_MODULE_1__libs_MicrophoneRecorder__[\"a\" /* default */](onStart, onStop, onSave, onData, options)\n      });\n    }\n  };\n\n  ReactMic.prototype.render = function render() {\n    var _props2 = this.props,\n        record = _props2.record,\n        onStop = _props2.onStop,\n        children = _props2.children;\n    var microphoneRecorder = this.state.microphoneRecorder;\n\n\n    if (microphoneRecorder) {\n      if (record) {\n        microphoneRecorder.startRecording();\n      } else {\n        microphoneRecorder.stopRecording(onStop);\n      }\n    }\n\n    return __WEBPACK_IMPORTED_MODULE_0_react___default.a.createElement(\n      __WEBPACK_IMPORTED_MODULE_0_react___default.a.Fragment,\n      null,\n      children\n    );\n  };\n\n  return ReactMic;\n}(__WEBPACK_IMPORTED_MODULE_0_react__[\"Component\"]);\n\n\n\n\nReactMic.defaultProps = {\n  className: \"record\",\n  audioBitsPerSecond: 128000,\n  mimeType: \"audio/webm;codecs=opus\",\n  record: false\n};\n\n/***/ }),\n/* 4 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nvar audioCtx = new (window.AudioContext || window.webkitAudioContext)();\nvar analyser = audioCtx.createAnalyser();\n\nvar AudioContext = {\n  getAudioContext: function getAudioContext() {\n    return audioCtx;\n  },\n  getAnalyser: function getAnalyser() {\n    return analyser;\n  }\n};\n\n/* harmony default export */ __webpack_exports__[\"a\"] = AudioContext;\n\n/***/ }),\n/* 5 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0__AudioContext__ = __webpack_require__(4);\n\n\nvar audioSource = void 0;\n\nvar AudioPlayer = {\n  create: function create(audioElem) {\n    var audioCtx = __WEBPACK_IMPORTED_MODULE_0__AudioContext__[\"a\" /* default */].getAudioContext();\n    var analyser = __WEBPACK_IMPORTED_MODULE_0__AudioContext__[\"a\" /* default */].getAnalyser();\n\n    if (audioSource === undefined) {\n      var source = audioCtx.createMediaElementSource(audioElem);\n      source.connect(analyser);\n      audioSource = source;\n    }\n\n    analyser.connect(audioCtx.destination);\n  }\n};\n\n/* harmony default export */ __webpack_exports__[\"a\"] = AudioPlayer;\n\n/***/ }),\n/* 6 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_audio_recorder_polyfill__ = __webpack_require__(1);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_audio_recorder_polyfill___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_audio_recorder_polyfill__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return MicrophoneRecorder; });\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\nvar mediaRecorder = void 0;\nvar chunks = [];\nvar startTime = void 0;\nvar mediaOptions = void 0;\nvar onStartCallback = void 0;\nvar onStopCallback = void 0;\nvar onSaveCallback = void 0;\nvar onDataCallback = void 0;\n\nvar constraints = { audio: true };\n\nnavigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n\nvar MicrophoneRecorder = function MicrophoneRecorder(onStart, onStop, onSave, onData, options) {\n  var _this = this;\n\n  _classCallCheck(this, MicrophoneRecorder);\n\n  this.startRecording = function () {\n    startTime = Date.now();\n    if (!mediaRecorder) {\n      if (navigator.mediaDevices) {\n        navigator.mediaDevices.getUserMedia(constraints).then(function (str) {\n          mediaRecorder = new __WEBPACK_IMPORTED_MODULE_0_audio_recorder_polyfill___default.a(str);\n          if (onStartCallback) {\n            onStartCallback();\n          }\n          mediaRecorder.addEventListener(\"dataavailable\", function (e) {\n            chunks = e.data;\n            if (onDataCallback) {\n              onDataCallback(e.data);\n            }\n          });\n\n          mediaRecorder.start();\n          mediaRecorder.addEventListener(\"stop\", _this.onStop);\n        });\n      } else {\n        alert(\"Your browser does not support audio recording\");\n      }\n    }\n  };\n\n  this.stopRecording = function () {\n    if (mediaRecorder) {\n      mediaRecorder.stop();\n      mediaRecorder.stream.getTracks()[0].stop();\n      mediaRecorder.stream.getTracks().forEach(function (i) {\n        return i.stop();\n      });\n    }\n    mediaRecorder = null;\n  };\n\n  this.onStop = function () {\n    var blobObject = {\n      blob: chunks,\n      startTime: startTime,\n      stopTime: window.Date.now(),\n      options: mediaOptions,\n      blobURL: window.URL.createObjectURL(chunks)\n    };\n    chunks = [];\n\n    if (onStopCallback) {\n      onStopCallback(blobObject);\n    }\n    if (onSaveCallback) {\n      onSaveCallback(blobObject);\n    }\n  };\n\n  onStartCallback = onStart;\n  onStopCallback = onStop;\n  onSaveCallback = onSave;\n  onDataCallback = onData;\n  mediaOptions = options;\n};\n\n\n\n/***/ }),\n/* 7 */\n/***/ (function(module, exports) {\n\nmodule.exports = __WEBPACK_EXTERNAL_MODULE_7__;\n\n/***/ }),\n/* 8 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(0);\n\n\n/***/ })\n/******/ ]);\n});\n\n\n// WEBPACK FOOTER //\n// react-mic.min.js"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// identity function for calling harmony imports with the correct context\n \t__webpack_require__.i = function(value) { return value; };\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 8);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap dfad4301de8ad1bfb379","import ReactMic from './components/ReactMic';\n\nexport default ReactMic;\n\n\n\n// WEBPACK FOOTER //\n// ./src/index.js","var AudioContext = window.AudioContext || window.webkitAudioContext\n\nfunction createWorker (fn) {\n  var js = fn\n    .toString()\n    .replace(/^function\\s*\\(\\)\\s*{/, '')\n    .replace(/}$/, '')\n  var blob = new Blob([js])\n  return new Worker(URL.createObjectURL(blob))\n}\n\nvar context\n\n/**\n * Audio Recorder with MediaRecorder API.\n *\n * @param {MediaStream} stream The audio stream to record.\n *\n * @example\n * navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {\n *   var recorder = new MediaRecorder(stream)\n * })\n *\n * @class\n */\nfunction MediaRecorder (stream) {\n  /**\n   * The `MediaStream` passed into the constructor.\n   * @type {MediaStream}\n   */\n  this.stream = stream\n\n  /**\n   * The current state of recording process.\n   * @type {\"inactive\"|\"recording\"|\"paused\"}\n   */\n  this.state = 'inactive'\n\n  this.em = document.createDocumentFragment()\n  this.encoder = createWorker(MediaRecorder.encoder)\n\n  var recorder = this\n  this.encoder.addEventListener('message', function (e) {\n    var event = new Event('dataavailable')\n    event.data = new Blob([e.data], { type: recorder.mimeType })\n    recorder.em.dispatchEvent(event)\n    if (recorder.state === 'inactive') {\n      recorder.em.dispatchEvent(new Event('stop'))\n    }\n  })\n}\n\nMediaRecorder.prototype = {\n  /**\n   * The MIME type that is being used for recording.\n   * @type {string}\n   */\n  mimeType: 'audio/wav',\n\n  /**\n   * Begins recording media.\n   *\n   * @param {number} [timeslice] The milliseconds to record into each `Blob`.\n   *                             If this parameter isn’t included, single `Blob`\n   *                             will be recorded.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * recordButton.addEventListener('click', function () {\n   *   recorder.start()\n   * })\n   */\n  start: function start (timeslice) {\n    if (this.state === 'inactive') {\n      this.state = 'recording'\n\n      if (!context) {\n        context = new AudioContext()\n      }\n      var input = context.createMediaStreamSource(this.stream)\n      var processor = context.createScriptProcessor(2048, 1, 1)\n\n      var recorder = this\n      processor.onaudioprocess = function (e) {\n        if (recorder.state === 'recording') {\n          recorder.encoder.postMessage([\n            'encode', e.inputBuffer.getChannelData(0)\n          ])\n        }\n      }\n\n      input.connect(processor)\n      processor.connect(context.destination)\n\n      this.em.dispatchEvent(new Event('start'))\n\n      if (timeslice) {\n        this.slicing = setInterval(function () {\n          if (recorder.state === 'recording') recorder.requestData()\n        }, timeslice)\n      }\n    }\n  },\n\n  /**\n   * Stop media capture and raise `dataavailable` event with recorded data.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * finishButton.addEventListener('click', function () {\n   *   recorder.stop()\n   * })\n   */\n  stop: function stop () {\n    if (this.state !== 'inactive') {\n      this.requestData()\n      this.state = 'inactive'\n      clearInterval(this.slicing)\n    }\n  },\n\n  /**\n   * Pauses recording of media streams.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * pauseButton.addEventListener('click', function () {\n   *   recorder.pause()\n   * })\n   */\n  pause: function pause () {\n    if (this.state === 'recording') {\n      this.state = 'paused'\n      this.em.dispatchEvent(new Event('pause'))\n    }\n  },\n\n  /**\n   * Resumes media recording when it has been previously paused.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * resumeButton.addEventListener('click', function () {\n   *   recorder.resume()\n   * })\n   */\n  resume: function resume () {\n    if (this.state === 'paused') {\n      this.state = 'recording'\n      this.em.dispatchEvent(new Event('resume'))\n    }\n  },\n\n  /**\n   * Raise a `dataavailable` event containing the captured media.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * this.on('nextData', function () {\n   *   recorder.requestData()\n   * })\n   */\n  requestData: function requestData () {\n    if (this.state !== 'inactive') {\n      this.encoder.postMessage(['dump', context.sampleRate])\n    }\n  },\n\n  /**\n   * Add listener for specified event type.\n   *\n   * @param {\"start\"|\"stop\"|\"pause\"|\"resume\"|\"dataavailable\"} type Event type.\n   * @param {function} listener The listener function.\n   *\n   * @return {undefined}\n   *\n   * @example\n   * recorder.addEventListener('dataavailable', function (e) {\n   *   audio.src = URL.createObjectURL(e.data)\n   * })\n   */\n  addEventListener: function addEventListener () {\n    this.em.addEventListener.apply(this.em, arguments)\n  },\n\n  /**\n   * Remove event listener.\n   *\n   * @param {\"start\"|\"stop\"|\"pause\"|\"resume\"|\"dataavailable\"} type Event type.\n   * @param {function} listener The same function used in `addEventListener`.\n   *\n   * @return {undefined}\n   */\n  removeEventListener: function removeEventListener () {\n    this.em.removeEventListener.apply(this.em, arguments)\n  },\n\n  /**\n   * Calls each of the listeners registered for a given event.\n   *\n   * @param {Event} event The event object.\n   *\n   * @return {boolean} Is event was no canceled by any listener.\n   */\n  dispatchEvent: function dispatchEvent () {\n    this.em.dispatchEvent.apply(this.em, arguments)\n  }\n}\n\n/**\n * Returns `true` if the MIME type specified is one the polyfill can record.\n *\n * This polyfill supports only `audio/wav`.\n *\n * @param {string} mimeType The mimeType to check.\n *\n * @return {boolean} `true` on `audio/wav` MIME type.\n */\nMediaRecorder.isTypeSupported = function isTypeSupported (mimeType) {\n  return /audio\\/wave?/.test(mimeType)\n}\n\n/**\n * `true` if MediaRecorder can not be polyfilled in the current browser.\n * @type {boolean}\n *\n * @example\n * if (MediaRecorder.notSupported) {\n *   showWarning('Audio recording is not supported in this browser')\n * }\n */\nMediaRecorder.notSupported = !navigator.mediaDevices || !AudioContext\n\n/**\n * Converts RAW audio buffer to compressed audio files.\n * It will be loaded to Web Worker.\n * By default, WAVE encoder will be used.\n * @type {function}\n *\n * @example\n * MediaRecorder.prototype.mimeType = 'audio/ogg'\n * MediaRecorder.encoder = oggEncoder\n */\nMediaRecorder.encoder = require('./wave-encoder')\n\nmodule.exports = MediaRecorder\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/audio-recorder-polyfill/index.js\n// module id = 1\n// module chunks = 0","// Copied from https://github.com/chris-rudmin/Recorderjs\n\nmodule.exports = function () {\n  var BYTES_PER_SAMPLE = 2\n\n  var recorded = []\n\n  function encode (buffer) {\n    var length = buffer.length\n    var data = new Uint8Array(length * BYTES_PER_SAMPLE)\n    for (var i = 0; i < length; i++) {\n      var index = i * BYTES_PER_SAMPLE\n      var sample = buffer[i]\n      if (sample > 1) {\n        sample = 1\n      } else if (sample < -1) {\n        sample = -1\n      }\n      sample = sample * 32768\n      data[index] = sample\n      data[index + 1] = sample >> 8\n    }\n    recorded.push(data)\n  }\n\n  function dump (sampleRate) {\n    var bufferLength = recorded.length ? recorded[0].length : 0\n    var length = recorded.length * bufferLength\n    var wav = new Uint8Array(44 + length)\n    var view = new DataView(wav.buffer)\n\n    // RIFF identifier 'RIFF'\n    view.setUint32(0, 1380533830, false)\n    // file length minus RIFF identifier length and file description length\n    view.setUint32(4, 36 + length, true)\n    // RIFF type 'WAVE'\n    view.setUint32(8, 1463899717, false)\n    // format chunk identifier 'fmt '\n    view.setUint32(12, 1718449184, false)\n    // format chunk length\n    view.setUint32(16, 16, true)\n    // sample format (raw)\n    view.setUint16(20, 1, true)\n    // channel count\n    view.setUint16(22, 1, true)\n    // sample rate\n    view.setUint32(24, sampleRate, true)\n    // byte rate (sample rate * block align)\n    view.setUint32(28, sampleRate * BYTES_PER_SAMPLE, true)\n    // block align (channel count * bytes per sample)\n    view.setUint16(32, BYTES_PER_SAMPLE, true)\n    // bits per sample\n    view.setUint16(34, 8 * BYTES_PER_SAMPLE, true)\n    // data chunk identifier 'data'\n    view.setUint32(36, 1684108385, false)\n    // data chunk length\n    view.setUint32(40, length, true)\n\n    for (var i = 0; i < recorded.length; i++) {\n      wav.set(recorded[i], i * bufferLength + 44)\n    }\n\n    recorded = []\n    postMessage(wav.buffer, [wav.buffer])\n  }\n\n  onmessage = function (e) {\n    if (e.data[0] === 'encode') {\n      encode(e.data[1])\n    } else {\n      dump(e.data[1])\n    }\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/audio-recorder-polyfill/wave-encoder.js\n// module id = 2\n// module chunks = 0","// cool blog article on how to do this: http://www.smartjava.org/content/exploring-html5-web-audio-visualizing-sound\n// https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\n\n// distortion curve for the waveshaper, thanks to Kevin Ennis\n// http://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion\n\nimport React, { Component } from \"react\";\nimport MicrophoneRecorder from \"../libs/MicrophoneRecorder\";\nimport AudioPlayer from \"../libs/AudioPlayer\";\n\nexport default class ReactMic extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      microphoneRecorder: null\n    };\n  }\n\n  componentDidMount() {\n    const { onSave, onStop, onStart, onData, audioElem, audioBitsPerSecond, mimeType } = this.props;\n    const options = {\n      audioBitsPerSecond,\n      mimeType\n    };\n\n    if (audioElem) {\n      AudioPlayer.create(audioElem);\n    } else {\n      this.setState({\n        microphoneRecorder: new MicrophoneRecorder(onStart, onStop, onSave, onData, options)\n      });\n    }\n  }\n\n  render() {\n    const { record, onStop, children } = this.props;\n    const { microphoneRecorder } = this.state;\n\n    if (microphoneRecorder) {\n      if (record) {\n        microphoneRecorder.startRecording();\n      } else {\n        microphoneRecorder.stopRecording(onStop);\n      }\n    }\n\n    return <React.Fragment>{children}</React.Fragment>;\n  }\n}\n\nReactMic.defaultProps = {\n  className: \"record\",\n  audioBitsPerSecond: 128000,\n  mimeType: \"audio/webm;codecs=opus\",\n  record: false\n};\n\n\n\n// WEBPACK FOOTER //\n// ./src/components/ReactMic.js","const audioCtx = new (window.AudioContext || window.webkitAudioContext)();\nconst analyser = audioCtx.createAnalyser();\n\nconst AudioContext  = {\n  getAudioContext() {\n    return audioCtx;\n  },\n\n  getAnalyser() {\n    return analyser;\n  }\n}\n\nexport default AudioContext;\n\n\n\n// WEBPACK FOOTER //\n// ./src/libs/AudioContext.js","import AudioContext from './AudioContext';\n\nlet audioSource;\n\nconst AudioPlayer =  {\n  create(audioElem) {\n    const audioCtx = AudioContext.getAudioContext();\n    const analyser = AudioContext.getAnalyser();\n\n    if(audioSource === undefined){\n      const source = audioCtx.createMediaElementSource(audioElem);\n      source.connect(analyser);\n      audioSource = source;\n    }\n\n    analyser.connect(audioCtx.destination);\n  }\n}\n\nexport default AudioPlayer;\n\n\n\n// WEBPACK FOOTER //\n// ./src/libs/AudioPlayer.js","import MediaRecorder from \"audio-recorder-polyfill\";\n\nlet mediaRecorder;\nlet chunks = [];\nlet startTime;\nlet mediaOptions;\nlet onStartCallback;\nlet onStopCallback;\nlet onSaveCallback;\nlet onDataCallback;\n\nconst constraints = { audio: true };\n\nnavigator.getUserMedia =\n  navigator.getUserMedia ||\n  navigator.webkitGetUserMedia ||\n  navigator.mozGetUserMedia ||\n  navigator.msGetUserMedia;\n\nexport default class MicrophoneRecorder {\n  constructor(onStart, onStop, onSave, onData, options) {\n    onStartCallback = onStart;\n    onStopCallback = onStop;\n    onSaveCallback = onSave;\n    onDataCallback = onData;\n    mediaOptions = options;\n  }\n\n  startRecording = () => {\n    startTime = Date.now();\n    if(!mediaRecorder) {\n      if (navigator.mediaDevices) {\n        navigator.mediaDevices.getUserMedia(constraints).then(str => {\n          mediaRecorder = new MediaRecorder(str);\n          if (onStartCallback) {\n            onStartCallback();\n          }\n          mediaRecorder.addEventListener(\"dataavailable\", e => {\n            chunks = e.data;\n            if (onDataCallback) {\n              onDataCallback(e.data);\n            }\n          });\n\n          mediaRecorder.start();\n          mediaRecorder.addEventListener(\"stop\", this.onStop);\n        });\n      } else {\n        alert(\"Your browser does not support audio recording\");\n      }\n    }\n  };\n\n  stopRecording = () => {\n    if (mediaRecorder) {\n      mediaRecorder.stop();\n      mediaRecorder.stream.getTracks()[0].stop();\n      mediaRecorder.stream.getTracks().forEach(i => i.stop());\n    }\n    mediaRecorder = null\n  };\n\n  onStop = () => {\n    const blobObject = {\n      blob: chunks,\n      startTime,\n      stopTime: window.Date.now(),\n      options: mediaOptions,\n      blobURL: window.URL.createObjectURL(chunks)\n    };\n    chunks = []\n\n    if (onStopCallback) {\n      onStopCallback(blobObject);\n    }\n    if (onSaveCallback) {\n      onSaveCallback(blobObject);\n    }\n  };\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/libs/MicrophoneRecorder.js","module.exports = __WEBPACK_EXTERNAL_MODULE_7__;\n\n\n//////////////////\n// WEBPACK FOOTER\n// external {\"root\":\"React\",\"commonjs2\":\"react\",\"commonjs\":\"react\",\"amd\":\"react\"}\n// module id = 7\n// module chunks = 0"],"sourceRoot":""}